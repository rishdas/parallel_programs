Q1) What common parallelism bug does this code appear to exhibit?

A: The common parallelism bug which  appears is no synhcronized access to shared
variables  i.e no  mutual exclusion.   The code  shared by  all the  threads are
worker_fun.  Which  in turn  has access to  shared/global variables.
/*
size_t num_threads, data_size;

volatile size_t round_num;

vector<uint32_t> data;
*/

Out  these global  variables  data_size  is read  only  and  num_threads is  not
accessed.  Vector  data and  variable round_num  is accessed  in read  and write
mode. These variables are accessed without synchronization between threads which
gives possiblilty for race condition.


2. Enter into the build/debug build  directory and compile the executables.  Run
the program pa1-dummy several times.

Q2) Describe at  least two different observed behaviors from  the program.  Does
the bug  identified in Question 1  explain the observed behavior?   Explain your
answer.



The two observed behaviours are :  1. Infinite loop due to unsynchronized access
to variable round_num.  2.  In correct Old  data hash picked up by a thread from
data vector again due unsynchronized access to data vector which is shared among
threads

Yes  the bug  in Question  1  explains the  behaviour.  A  little more  detailed
analysis on the behaviour.

1.  This infinite loop occurs because of the type of variable round_num which is
size_t  which is  a unsigned  integer  typedefed. As  it  can be  seen that  the
round_num is decremented at  the end of each iteration of  the outer while loop.
If we add a  print statement to print the value of round_num  along with old and
new hash value we can see that it starts from num_rounds which in my case was 64
and goes to zero and beyond which  is ffffffffffffffff ......  because 0-- of an
unsigned integer is  ffffffffffffffff which is greater than zero  hence the loop
continues.  Hence  at the  time of condition  checking it is  zero as  any other
thread may have decremented the value from zero to all ffffffffffffffff which is
a  wrap   around  hence  the   infinte  loop.

[Thread 1]: Old data hash: 0xfb264c24round_num: 0
[Thread 3]: Old data hash: 0xca81cbe0round_num: 0
[Thread 3]: New data hash: 0x3be9a4a6round_num: 0

[Thread 1]: New data hash: 0xca81cbe0round_num: 0

[Thread 1]: Old data hash: 0x3be9a4a6round_num: fffffffffffffffe
[Thread 1]: New data hash: 0xc9da84fbround_num: fffffffffffffffe

[Thread 3]: Old data hash: 0xc9da84fbround_num: fffffffffffffffd
[Thread 3]: New data hash: 0x50efe25dround_num: fffffffffffffffd

[Thread 1]: Old data hash: 0x50efe25dround_num: fffffffffffffffc
[Thread 1]: New data hash: 0x31050194round_num: fffffffffffffffc

[Thread 3]: Old data hash: 0x31050194round_num: fffffffffffffffb
[Thread 3]: New data hash: 0xe3796f19round_num: fffffffffffffffb


2. Desired behaviour:

[Thread 2]: Old data hash: 0x54443e18
[Thread 2]: New data hash: 0xb6f75de5 -- Value A

[Thread 3]: Old data hash: 0xb6f75de5 -- Value B
[Thread 3]: New data hash: 0xd31cd8c8

Produced Behaviour in some cases:

[Thread 1]: New data hash: 0xe654929b

[Thread 3]: Old data hash: 0x9103486e
[Thread 3]: New data hash: 0x80a11d8b

This could  also be  due to interleaving  IO statements but  never the  less the
reason is unsyncronized access to shared  variable data. Were the there could be
interleaving double  writes before read which  could give rise to  such diffrent
old and new values between rounds.


3.     Read     the    documentation     for    Clang’s     Thread    Sanitizer:
     https://clang.llvm.org/docs/ThreadSanitizer.html     Q3)    What     common
     parallelism issue(s) does the Thread Sanitizer help to detect?  Q4) What is
     the typical slowdown of an application  when it is compiled with the Thread
     Sanitizer?  Q5)  What command line  option needs to  be passed to  Clang to
     compile an  executable with  the Thread Sanitizer?   Q6) What  command line
     option is implied by the use of the Thread Sanitizer?

A3) Thread  Sanitizer helps  you detect  data races by  giving warnings  such as
these : WARNING: ThreadSanitizer: data race (pid=6785)

A4) The typical  slowdown of an application when compiled  with thread sanitizer
is 5x-15x.

A5) -fsanitize=thread is  the command line option passed to  clang to compile an
executable. Additiional  parameters like -O1  -g are also passed  for perfomance
and output readability purposes.

A6)  As non-position  independant executables  are not  supported by  the thread
sanitizer therefore  by adding  -fsanitize=thread flag  implictly adds  -fPIE if
-fPIC has not been mentioned as a flag and -pie flag if linking an executable.




4.   Switch  to the  build/tsan  directory,  compile  the executables,  and  run
pa1-dummy several times.  Q7) What bug(s) was detected, and what line(s) of code
does the tool blame for the bug(s)?

Error type 1:
WARNING: ThreadSanitizer: data race (pid=6785)
  Read of size 4 at 0x7f3168b7ef60 by thread T2:
 #3 worker_fun(unsigned long) /home/sirdas/parallel_programs/pa1-src/pa1.cpp:109 (pa1-dummy+0x0000004ad5a0)

Line no 109: 	tout(tid) << "Entering thread." << endl;
basic_ostream<char>& type object returned by tout is the reason for data race.


Error Type 2:

==================
WARNING: ThreadSanitizer: data race (pid=6785)
  Read of size 8 at 0x000001544360 by thread T2:
  #0 worker_fun(unsigned long) /home/sirdas/parallel_programs/pa1-src/pa1.cpp:116 (pa1-dummy+0x0000004ad68a)

Line no 116: while (round_num > 0) {
This is because of unsyncronized access to global variable round_num.


Error Type 3:

WARNING: ThreadSanitizer: data race (pid=6785)
  Read of size 4 at 0x7d900000fffc by thread T2:
    #0 worker_fun(unsigned long) /home/sirdas/parallel_programs/pa1-src/pa1.cpp:125 (pa1-dummy+0x0000004ad75b)

    
Line no 125: update_hash_state(old_state, data[index]);

Again unsynchronized access to data which is a global structure.


5. Open  the files locks.cpp and  locks.h. Several locations in  these files are
marked with FIXME com- ments. Implement  Peterson’s Filter Lock (pg. 28) and the
Bakery Lock (pg. 30) by filling these locations in with function definitions and
class members.


A. Done. Please Refer Source code.


6.  Notice that all of our locks  conform to the same interface. This means that
we  can  test multiple  lock  types  using the  same  source  program simply  by
re-defining lock t, which  is exactly what pa1.cpp does. Use the  type lock t to
enforce mutual exclusion in pa1.cpp.  The pa1-dummy program should still exhibit
any previously  present bugs, but the  other executables should now  be properly
synchronized.
Q8) Could the critical sections you identified be made larger? If so, what would
be  the advantages  and  disadvantages?
Q9) Could  the critical sections  you identified be  made smaller?  If  so, what
would be the advantages and disadvantages?



A8) The  changes I have  made is the  largest possible critical  section without
altering behaviour of  the program. Encompassing the whole of  worker_fun as one
critical section would reomve all the direct worker_fun thread warnings but this
would alter the behaviour of the program  as in round_num is a data structure to
be  shared accross  threads and  thus  rounds are  expected to  be shared  among
threads. If we place the whole function body in critical section once one thread
takes control  of critical  section it will  run all the  rounds and  exit after
which other  threads even  though enter  critical section  but dont  perform any
computation task which kind of alters  the program behaviour.  The advantages of
having a  larger critical  section is  low overhead  involved in  contention for
accquiring  lock.  The  disadvantages of  having  a larger  critical section  is
lesser fraction of  code being paralliezed hence low  speedup according Amdahl's
Law.

A9) Yes the critical sections can be  smaller than the one I have already coded.
The critical  section could  be specicially  around access  to each  shared data
structure like tout,  data, round_num. but have too many  small critical section
comes with  contention overhead.   The advantages of  small critical  section as
mentioned earlier  is more  parallelism hence  theoritcal increased  speedup via
Amdahl's Law if thread contention  overhead is negligible.  The disadvantages of
small critical section is more overhead for thread contention.


7. Enter the build/tsan directory, compile  the executables, and test your locks
to ensure that the thread sanitizer no longer detects any errors.


./pa1-std 4 100 2048

Runs properly to completion with each thread doing some computation
This establishes that the placement of lock and unlock statement in pa1.cpp is
correct.

For petersons and bakery the thread analyzer does show warnings as the lock/unlock
procedure of both are not atmoic hence dont conform with the thread sanitizer.
Below I descibe the warnings and justification as to why they can ignored.

./pa1-petersons 4 100 2048

The thread sanitizer in this case reports 9 warnings.
=========
ThreadSanitizer: reported 9 warnings
=========


Warning 1: void PetersonsFilterLock::lock(void)

locks.cpp: Line No 60: level[me] = i;

This is because it concurrent access is on independant data fields as this line
accesses level[me] were me is thread_id which is diffrent for each thread.
Hence this warning can be ignored.

Warning 2: void PetersonsFilterLock::lock(void)

locks.cpp: Line No 61: victim[i] = me;

Here victim is again a shared data structure and i denotes the level the current
thread is trying to enter. Even though all threads may try to simultaneously set
the values in victim only one of them is able to set a value and then enter the
while loop(busy wait). Others who set previous values dont enter the while loop
instead go to the next level by undergoing another iteration of for.

while (sameOrHigher(me, i) && victim[i] == me);

Hence concurrent access to victim is sort necessary and accepted behaviour for
this algorthim.

Warning 3: bool PetersonsFilterLock::sameOrHigher(size_t me, size_t i)

locks.cpp: Line No 73: if (k != me && level[k] >= i) {

Here victim is again access to shared data structure level as was in Warning 1 but
here there is overlap in access. But this overlap in access is again a necessary
and accepted behaviour i.e even if the result of this loop is erroneos true.
The lock procedure has another check on it which is victim[i] == me which allows
only one thread to be consumed per level. Hence again this warning can be ignored.

Warning 4: void worker_fun(size_t tid)

pa1.cpp: Line no 126: 	tout(tid) << "Entering thread." << endl;

This warning is direct result of the previous 3 warnings as we assume are lock
procedure works fine with warnings so we can assume this works fine as well.
The explanation for this warning without locks is in A7

Warning 5: void worker_fun(size_t tid)

pa1.cpp: Line no 143: 	if (round_num > 0) {

This warning is direct result of the previous 3 warnings as we assume are lock
procedure works fine with warnings so we can assume this works fine as well.
The explanation for this warning without locks is in A7

Warning 6: void worker_fun(size_t tid)

pa1.cpp: Line no 147: 	update_hash_state(old_state, data[index]);

This warning is direct result of the previous 3 warnings as we assume are lock
procedure works fine with warnings so we can assume this works fine as well.
The explanation for this warning without locks is in A7


./pa1-bakery 4 100 2048

Warning 1: size_t BakeryLock::maxLabel()

locks.cpp: Line No 111: if (label[i] > max) {


This statement can be executed concurrently by all the threads thus resulting
in the same max value for more than one thread. But this tie is broken by call
to procedure isLabelLessThan which performs additional check of k<i in case the
label is found to be the same using that as tie breaker. This is accepted behaviour
in the algorithm hence the warning can be ignored.


Warning 2: void worker_fun(size_t tid)

pa1.cpp: Line no 126: 	tout(tid) << "Entering thread." << endl;

This warning is direct result of the previous 3 warnings as we assume are lock
procedure works fine with warnings so we can assume this works fine as well.
The explanation for this warning without locks is in A7

Warning 3: void BakeryLock::unlock(void)


locks.cpp: Line No 105: flag[thread_id] = false;


This line is flagged as warning because it has concurrent access to shared data
structure flag[]. This access is on individual elements of the array based on
thread id which is mutually exclusive. Hence this warning can be ignored.


Warning 4: void BakeryLock::lock(void)

locks.cpp: Line No 96:  flag[i] = true;

Again this is similar to Warning 3.
This line is flagged as warning because it has concurrent access to shared data
structure flag[]. This access is on individual elements of the array based on
thread id which is mutually exclusive. Hence this warning can be ignored.


Warning 5: void BakeryLock::lock(void)

locks.cpp: Line No 97:  label[i] = maxLabel() + 1;

Again this is similar to Warning 3 and 4 as each thread accesses label array
based on thread id whcih is mutually exclusive.


Warning 6: void worker_fun(size_t tid)

pa1.cpp: Line no 143: 	if (round_num > 0) {

This warning is direct result of the previous 3 warnings as we assume are lock
procedure works fine with warnings so we can assume this works fine as well.
The explanation for this warning without locks is in A7

Warning 7: void worker_fun(size_t tid)

pa1.cpp: Line no 147: 	update_hash_state(old_state, data[index]);

This warning is direct result of the previous 3 warnings as we assume are lock
procedure works fine with warnings so we can assume this works fine as well.
The explanation for this warning without locks is in A7



8.   Enter the  build/release directory  and compile  the executables.
Next,  benchmark  pa1-petersons,  pa1-bakery,  and  pa1-std  with  the
following parameters:
(a) A fixed round  count of 100
(b)  Data sizes 2^10  (1024), 2^18  (262144), and  2^20 (1048576)
(c) Number  of threads ranging from 2 to 128, by powers of two 2
  
When benchmarking, run each program 6  times, drop the first time, and
average the remaining times. Once  you have collected your data create
three line graphs, one for each data size, comparing the total elapsed
time versus the number of threads.

Q10) On average, which lock  performed best? Were there any situations
where it was not the best lock?

Q11) Which lock had better  performance: Peterson’s Filter Lock or the
Bakery Lock?

Q12) Was the  relative performance of the locks the  same for all data
sizes? Explain why or why not.


Note: I  faced problems  with pa1-bakery  binary generated  in release
folder.  The  bakery binary  halted midway and  hence was  stuck. This
behaviour was not seen in  either build/tsan or build/debug. Hence all
my  results   are  generated  for  build/debug   binaries  instead  of
build/release.

I have used a crude Python Script to collect the benchmark results and
used https://plot.ly to build line graphs. The script is written below
and its also present in my source ditectory named pa1-benchmark.py. To
run it it needs to be placed in build/debug directory.

==========================================
from subprocess import Popen, PIPE
import os

sum_e = 0
num_of_rounds = '100'
num_of_threads = 2
data_sizes = ['1024', '262144', '1048576']
binary_l = ['./pa1-std', './pa1-petersons', './pa1-bakery']
ctr = 0
for binary in binary_l:
    for data_size in data_sizes:
        while num_of_threads <= 128:
            for num in range(0,6):
                p = Popen(['time', binary, str(num_of_threads), num_of_rounds, data_size], stdin=PIPE, stdout=PIPE, stderr=PIPE)
                out, err = p.communicate()
                exitcode = p.returncode
                if ctr == 0:
                    ctr = ctr + 1
                    continue
                #print err + " "
                time_e = 3600*float(err.split()[2].split(':')[0]) + 60*float(err.split()[2].split(':')[1].split('e')[0].split('.')[0]) + float(err.split()[2].split(':')[1].split('e')[0].split('.')[1])
                sum_e = sum_e + float(time_e)
                ctr = ctr + 1
            print data_size + " " + str(num_of_threads) + " " + str(sum_e/5)
            num_of_threads *= 2
            ctr = 0
            sum_e = 0
        num_of_threads = 2
================================

System Parameters:

The results have been collected on
Ubuntu(Lubuntu) 16.04 VM(Virtual Machine) on MacBook Pro Machine
with specs : 2.7 GHz Intel Core i5, 8 GB 1867 MHz DDR3

VMM: Oracle Virtual Box

VM Specs:
CPU Cores : 2
Base Memory : 2048 MB
Acceleration : VT-x/AMD-V, Nested Paging, KVM Paravirtualization

================================
Results: Output of Script (Format  <datasize> <no of threads> <time in
seconds>) If you  are not interested in no's please  skip this section
and checkout the .png files in source directory.
//Line graphs
pa1-petersons_1024.png
pa1-petersons_1048576.png
pa1-petersons_262144.png
pa1-std_1024.png
pa1-std_1048576.png
pa1-std_262144.png
pa1-bakery_1024.png
pa1-bakery_1048576.png
pa1-bakery_262144.png
//Data corresponding to the line graphs
//pa1-std
1024 2 1.6
1024 4 2.0
1024 8 2.0
1024 16 2.2
1024 32 2.0
1024 64 2.2
1024 128 2.2
262144 2 320.2
262144 4 343.2
262144 8 317.0
262144 16 322.6
262144 32 318.0
262144 64 340.6
262144 128 319.2
1048576 2 1159.4
1048576 4 1164.6
1048576 8 1123.8
1048576 16 1128.4
1048576 32 1146.2
1048576 64 1129.4
1048576 128 1133.6
//pa1-petersons
1024 2 2.2
1024 4 13.8
1024 8 45.4
1024 16 46.2
1024 32 55.2
1024 64 80.6
1024 128 279.0
262144 2 284.0
262144 4 558.8
262144 8 1119.8
262144 16 2199.4
262144 32 4404.8
262144 64 8872.4
262144 128 17850.6
1048576 2 1100.6
1048576 4 2182.4
1048576 8 4370.2
1048576 16 8711.6
1048576 32 17443.0
1048576 64 34705.4
1048576 128 69771.8
//pa1-bakery
1024 2 2.0
1024 4 41.0
1024 8 84.2
1024 16 107.4
1024 32 209.4
1024 64 471.6
1024 128 1155.0
262144 2 285.4
262144 4 560.4
262144 8 1113.0
262144 16 2201.0
262144 32 4365.6
262144 64 8755.6
262144 128 18605.0
1048576 2 1151.2
1048576 4 2201.8
1048576 8 4446.2
1048576 16 9634.6
1048576 32 17447.0
1048576 64 34958.2
1048576 128 70701.2

==================================================

A10)
On an average the pa1-std i.e the standard lock provided by C++ library
performs the best. Yes there were situations for which this was not the best lock.
If you look at the results above:
For pa1-std
<datasize> <no of threads> <time in seconds>
262144           2             320.2
For pa1-petersons
<datasize> <no of threads> <time in seconds>
262144           2             284.0
For pa1-bakery
<datasize> <no of threads> <time in seconds>
262144           2             285.4

For pa1-std
<datasize> <no of threads> <time in seconds>
1048576           2             1159.4
For pa1-petersons
<datasize> <no of threads> <time in seconds>
1048576           2             1100.6
For pa1-bakery
<datasize> <no of threads> <time in seconds>
1048576           2             1151.2


As you can see for these parameters bakery and petersons performed better than
standard lock.


A11)

The relative performance of bakery and petersons differs with data size.
For:
1024 : Petersons is clear winner as the no of threads increase 
262144 : Bakery and petersons more or less deliver the same perfomance.
1048576 :  Here again Bakery  and petersons  more or less  deliver the
same perfomance.

A13)

No the  the relative  performance of  the locks is  not the  same. The
standard  lock  is faster  than  petersons  and  bakery for  all  data
sizes. Bakery or petersons on the other  hand is more or less the same
for 262144 and 1048576 data size.  But for data size 1024 petersons is
relatively  better  than bakery.  The  reason  standard lock  performs
better  is  its  a  mutex   lock  internally  which  implements  loack
atomically  and does  not have  to go  through a  loop of  making each
thread wait at some level like petersons  or a loop of finding the max
level like bakery does.

